{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b7a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412f2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "def Upsample(dim):\n",
    "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2d(dim, dim, 4, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37aa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b056c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups = 8):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(dim, dim_out, 3, padding = 1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, scale_shift = None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if exists(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n",
    "        super().__init__()\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out))\n",
    "            if exists(time_emb_dim)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.block1(x)\n",
    "\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            h = rearrange(time_emb, \"b c -> b c 1 1\") + h\n",
    "\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):\n",
    "        super().__init__()\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))\n",
    "            if exists(time_emb_dim)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.GroupNorm(1, dim) if norm else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out * mult, 3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.GroupNorm(1, dim_out * mult),\n",
    "            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.ds_conv(x)\n",
    "\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            assert exists(time_emb) \n",
    "            condition = self.mlp(time_emb)\n",
    "            h = h + rearrange(condition, \"b c -> b c 1 1\")\n",
    "\n",
    "        h = self.net(h)\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc2908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k)\n",
    "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
    "        attn = sim.softmax(dim=-1)\n",
    "\n",
    "        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),\n",
    "                                    nn.GroupNorm(1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "\n",
    "        q = q.softmax(dim=-2)\n",
    "        k = k.softmax(dim=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
    "\n",
    "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
    "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f8af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.GroupNorm(1, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5273e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        init_dim=None,\n",
    "        out_dim=None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        channels=3,\n",
    "        with_time_emb=True,\n",
    "        resnet_block_groups=8,\n",
    "        use_convnext=True,\n",
    "        convnext_mult=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "\n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        if use_convnext:\n",
    "            block_klass = partial(ConvNextBlock, mult=convnext_mult)\n",
    "        else:\n",
    "            block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
    "\n",
    "        # time embeddings\n",
    "        if with_time_emb:\n",
    "            time_dim = dim * 4\n",
    "            self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(dim),\n",
    "                nn.Linear(dim, time_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(time_dim, time_dim),\n",
    "            )\n",
    "        else:\n",
    "            time_dim = None\n",
    "            self.time_mlp = None\n",
    "\n",
    "        # layers\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                        Downsample(dim_out) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                        Upsample(dim_in) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        out_dim = default(out_dim, channels)\n",
    "        self.final_conv = nn.Sequential(\n",
    "            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
    "\n",
    "        h = []\n",
    "\n",
    "        # downsample\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        # bottleneck\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        # upsample\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf8f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "def quadratic_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2\n",
    "\n",
    "def sigmoid_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    betas = torch.linspace(-6, 6, timesteps)\n",
    "    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89e951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 200\n",
    "\n",
    "# define beta schedule\n",
    "betas = linear_beta_schedule(timesteps=timesteps)\n",
    "\n",
    "# define alphas\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975c9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Lambda, ToPILImage, CenterCrop, Resize\n",
    "\n",
    "image_size = 128\n",
    "transform = Compose([\n",
    "    Resize(image_size),\n",
    "    CenterCrop(image_size),\n",
    "    ToTensor(), # turn into Numpy array of shape HWC, divide by 255\n",
    "    Lambda(lambda t: (t * 2) - 1),\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09bc8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_transform = Compose([\n",
    "     Lambda(lambda t: (t + 1) / 2),\n",
    "     Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "     Lambda(lambda t: t * 255.),\n",
    "     Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "     ToPILImage(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244cfd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward diffusion\n",
    "def q_sample(x_start, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "\n",
    "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x_start.shape\n",
    "    )\n",
    "\n",
    "    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79855dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_image(x_start, t):\n",
    "    x_noisy = q_sample(x_start, t=t)\n",
    "    noisy_image = reverse_transform(x_noisy.squeeze())\n",
    "\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fb73e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use seed for reproducability\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# source: https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
    "def plot(imgs, with_orig=False, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(figsize=(200,200), nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [image] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "        \n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc1855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_losses(denoise_model, x_start, t, noise=None, loss_type=\"l1\"):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "\n",
    "    x_noisy = q_sample(x_start=x_start, t=t, noise=noise)\n",
    "    predicted_noise = denoise_model(x_noisy, t)\n",
    "\n",
    "    if loss_type == 'l1':\n",
    "        loss = F.l1_loss(noise, predicted_noise)\n",
    "    elif loss_type == 'l2':\n",
    "        loss = F.mse_loss(noise, predicted_noise)\n",
    "    elif loss_type == \"huber\":\n",
    "        loss = F.smooth_l1_loss(noise, predicted_noise)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "276f9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load dataset from the hub\n",
    "dataset = load_dataset(\"fashion_mnist\")\n",
    "image_size = 28\n",
    "channels = 1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beb54e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# define image transformations (e.g. using torchvision)\n",
    "transform = Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "])\n",
    "\n",
    "# define function\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [transform(image.convert(\"L\")) for image in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "\n",
    "    return examples\n",
    "\n",
    "transformed_dataset = dataset.with_transform(transforms).remove_columns(\"label\")\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330ac8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pixel_values'])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8cc28c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def p_sample(model, x, t, t_index):\n",
    "    betas_t = extract(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
    "\n",
    "    # Equation 11 in the paper\n",
    "    # Use our model (noise predictor) to predict the mean\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "\n",
    "    if t_index == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
    "        noise = torch.randn_like(x)\n",
    "        # Algorithm 2 line 4:\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
    "\n",
    "# Algorithm 2 but save all images:\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(model, shape):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    b = shape[0]\n",
    "    # start from pure noise (for each example in the batch)\n",
    "    img = torch.randn(shape, device=device)\n",
    "    imgs = []\n",
    "\n",
    "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
    "        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
    "        imgs.append(img.cpu().numpy())\n",
    "    return imgs\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, image_size, batch_size=16, channels=3):\n",
    "    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b781cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "results_folder = Path(\"./results\")\n",
    "results_folder.mkdir(exist_ok = True)\n",
    "save_and_sample_every = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28a941e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Unet(\n",
    "    dim=image_size,\n",
    "    channels=channels,\n",
    "    dim_mults=(1, 2, 4,)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "955480ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a2e5b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4444088637828827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▍                                                              | 102/469 [00:22<00:58,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12980438768863678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▍                                             | 202/469 [00:38<00:43,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.08470866084098816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▌                            | 302/469 [00:54<00:27,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05911758914589882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████▌           | 402/469 [01:11<00:11,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05860556662082672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:23<00:00,  5.64it/s]\n",
      "  0%|▎                                                                                 | 2/469 [00:00<01:19,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.06548312306404114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▍                                                              | 102/469 [00:17<01:00,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05219642445445061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▍                                             | 202/469 [00:33<00:44,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04395053908228874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▌                            | 302/469 [00:50<00:27,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.061113279312849045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████▌           | 402/469 [01:07<00:11,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04620102420449257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:19<00:00,  5.92it/s]\n",
      "  0%|▎                                                                                 | 2/469 [00:00<01:21,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05146124213933945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▍                                                              | 102/469 [00:17<01:01,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.054186224937438965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▍                                             | 202/469 [00:34<00:45,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04692232236266136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▌                            | 302/469 [00:51<00:28,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05043544992804527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████▌           | 402/469 [01:08<00:11,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0468808189034462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:20<00:00,  5.86it/s]\n",
      "  0%|▎                                                                                 | 2/469 [00:00<01:22,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.054957758635282516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▍                                                              | 102/469 [00:17<01:01,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04562012478709221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▍                                             | 202/469 [00:34<00:44,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04666200280189514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▌                            | 302/469 [00:51<00:27,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04228605329990387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████▌           | 402/469 [01:08<00:11,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.041267190128564835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:20<00:00,  5.86it/s]\n",
      "  0%|▎                                                                                 | 2/469 [00:00<01:22,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04226566106081009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▍                                                              | 102/469 [00:17<01:02,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04906478151679039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▍                                             | 202/469 [00:34<00:44,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04521374776959419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▌                            | 302/469 [00:51<00:27,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0419328548014164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████▌           | 402/469 [01:08<00:11,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04766446724534035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:20<00:00,  5.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, batch in enumerate(tqdm(dataloader)):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      batch_size = batch[\"pixel_values\"].shape[0]\n",
    "      batch = batch[\"pixel_values\"].to(device)\n",
    "\n",
    "      # Algorithm 1 line 3: sample t uniformally for every example in the batch\n",
    "      t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
    "\n",
    "      loss = p_losses(model, batch, t, loss_type=\"huber\")\n",
    "\n",
    "      if step % 100 == 0:\n",
    "        print(\"Loss:\", loss.item())\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # save generated images\n",
    "      if step != 0 and step % save_and_sample_every == 0:\n",
    "        milestone = step // save_and_sample_every\n",
    "        batches = num_to_groups(4, batch_size)\n",
    "        all_images_list = list(map(lambda n: sample(model, batch_size=n, channels=channels), batches))\n",
    "        all_images = torch.cat(all_images_list, dim=0)\n",
    "        all_images = (all_images + 1) * 0.5\n",
    "        save_image(all_images, str(results_folder / f'sample-{milestone}.png'), nrow = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2bc5396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|███████████████████████████████████████████████████████| 200/200 [00:06<00:00, 32.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# sample 64 images\n",
    "samples = sample(model, image_size=image_size, batch_size=64, channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f735a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x159df6742e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a random one\n",
    "random_index = 5\n",
    "plt.imshow(samples[-1][random_index].reshape(image_size, image_size, channels), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1754a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "random_index = 53\n",
    "\n",
    "fig = plt.figure()\n",
    "ims = []\n",
    "for i in range(timesteps):\n",
    "    im = plt.imshow(samples[i][random_index].reshape(image_size, image_size, channels), cmap=\"gray\", animated=True)\n",
    "    ims.append([im])\n",
    "\n",
    "animate = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
    "animate.save('diffusion.gif')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8fbc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
