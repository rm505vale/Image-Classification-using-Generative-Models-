{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  tqdm import tqdm\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import idx2numpy\n",
    "\n",
    "\n",
    "images_root_folder = \"images-fashion-MLP-VAE\"\n",
    "\n",
    "if not os.path.exists(f\"{images_root_folder}\"):\n",
    "    os.mkdir(f\"{images_root_folder}\")\n",
    "\n",
    "\n",
    "# Load the labels file\n",
    "trainPath = \"fashion-MNIST/train-images-idx3-ubyte\"\n",
    "testPath = \"fashion-MNIST/t10k-images-idx3-ubyte\"\n",
    "\n",
    "train = idx2numpy.convert_from_file(trainPath)\n",
    "test = idx2numpy.convert_from_file(testPath)\n",
    "train=torch.Tensor(train)\n",
    "test=torch.Tensor(test)\n",
    "train=torch.flatten(train,start_dim=1)\n",
    "test=torch.flatten(test,start_dim=1)\n",
    "label=\"fashion-MNIST/train-labels-idx1-ubyte\"\n",
    "labels=idx2numpy.convert_from_file(label)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "PATH=\"MLP-VAE-Fashion_MNIST-Dataset-Model\"\n",
    "EPOCHS=50\n",
    "learning_rate_encoder=0.001\n",
    "learning_rate_maniksoft=0.01\n",
    "latent_dim=64\n",
    "beta = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d062b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class VariationalEnc(nn.Module):\n",
    "    def __init__(self,x):\n",
    "        super(VariationalEnc, self).__init__()\n",
    "        self.l1=nn.Linear(784,512)\n",
    "        self.l2=nn.Linear(512,x)\n",
    "        self.l3=nn.Linear(512,x)\n",
    "        self.dis=torch.distributions.Normal(0, 1)\n",
    "        self.dis.loc = self.dis.loc.cuda() # hack to get sampling on the GPU\n",
    "        self.dis.scale = self.dis.scale.cuda()\n",
    "        self.kld=0\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        mu=self.l2(x)\n",
    "        sig=torch.exp(self.l3(x))\n",
    "        z=mu + sig*self.dis.sample(mu.shape)\n",
    "        self.kld=(sig**2 + mu**2 - torch.log(sig) - 1/2).sum()\n",
    "        return z\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,x):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.l1=nn.Linear(x,512)\n",
    "        self.l2=nn.Linear(512,784)\n",
    "\n",
    "    def forward(self,x):\n",
    "        ans=self.l1(x)\n",
    "        ans=F.relu(ans)\n",
    "        ans=self.l2(ans)\n",
    "        ans = torch.sigmoid(ans)\n",
    "        return ans\n",
    "\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,x):\n",
    "        super(VAE, self).__init__()\n",
    "        self.enc=VariationalEnc(x)\n",
    "        self.dec=Decoder(x)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.enc(x)\n",
    "        return self.dec(x)\n",
    "\n",
    "\n",
    "def chaap2(orignal,decoded, idx, epo):\n",
    "    if not os.path.exists(f\"{images_root_folder}/{epo}\"):\n",
    "        os.mkdir(f\"{images_root_folder}/{epo}\")\n",
    "\n",
    "    org1=torch.tensor(orignal)\n",
    "    org1=org1.detach().cpu().numpy()\n",
    "    org1=np.resize(org1,(28,28))\n",
    "\n",
    "    dec1=torch.tensor(decoded)\n",
    "    dec1=dec1.detach().cpu().numpy()\n",
    "    dec1=np.resize(dec1,(28,28))\n",
    "\n",
    "    output_path = f\"{images_root_folder}/{epo}/{idx}\"\n",
    "    if not os.path.exists(f\"{output_path}\"):\n",
    "        os.mkdir(f\"{output_path}\")\n",
    "\n",
    "    plt.imsave(f\"{output_path}/original.png\" , org1, cmap='gray')\n",
    "    plt.imsave(f\"{output_path}/decoded.png\" , dec1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b997b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "    def __init__(self,x):\n",
    "        super(Softmax, self).__init__()\n",
    "        self.layer_64_1024 = nn.Linear(latent_dim, 1024)\n",
    "        self.layer_1024_10 = nn.Linear(1024, 10)\n",
    "    \n",
    "    def forward(self,z):\n",
    "        z = self.layer_64_1024(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.layer_1024_10(z)\n",
    "        return z\n",
    "\n",
    "def getEncodedData(train):\n",
    "    encoded_train = []\n",
    "    for x in tqdm(train):\n",
    "        x=x/255\n",
    "        x=x.to(torch.float32)\n",
    "        x = x.to(device) # GPU\n",
    "        xx=manik.enc.forward(x)\n",
    "        encoded_train.append(xx)\n",
    "    return encoded_train\n",
    "    \n",
    "#manik = VAE(latent_dim).to(device)\n",
    "#manik.load_state_dict(torch.load(\"MLP-VAE-Fashion_MNIST-Dataset-Model\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143fc9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = getEncodedData(train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(labels):\n",
    "    encoded_train[i]=torch.cat((encoded_train[i],torch.tensor([x]).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18e139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4359dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = [x.detach().cpu() for x in encoded_train]\n",
    "encoded_train=np.array(encoded_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0874eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = np.array([np.array(x) for x in encoded_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(encoded_train[:,:-1], encoded_train[:,-1], test_size=0.95, random_state=42,stratify=encoded_train[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412619ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs=100\n",
    "softmanik = Softmax(64).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(softmanik.parameters(), lr=0.001)\n",
    "y_train = np.array(y_train,dtype=np.int32)\n",
    "for epoch in tqdm(range(100)):\n",
    "    for i,x in enumerate(X_train):\n",
    "        x = torch.tensor(x).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = softmanik.forward(x)\n",
    "        loss = criterion(outputs, torch.tensor(y_train[i],dtype=torch.long).to(device))\n",
    "        loss.backward()\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"maniksoft2\"\n",
    "torch.save(softmanik.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a432a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bb4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5dfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd51cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6dd5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "manik=VAE(latent_dim).to(device)\n",
    "opt = torch.optim.Adam(manik.parameters(), lr=0.001)\n",
    "# optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    for idx,x in enumerate(tqdm(train)):\n",
    "        opt.zero_grad()\n",
    "        x=x/255\n",
    "        x=x.to(torch.float32)\n",
    "        x = x.to(device) # GPU\n",
    "        xx=manik.forward(x)\n",
    "#         print(xx)\n",
    "\n",
    "        if(idx % 1000 == 0 or idx == train.shape[0]-1):\n",
    "            chaap2(x,xx, idx, i)\n",
    "\n",
    "#         print(x)\n",
    "\n",
    "        #losses=torch.linalg.norm(xx-x,2)/784 + vaenc.enc.kld\n",
    "        losses = ((x - xx)**2).sum() + beta*manik.enc.kld\n",
    "\n",
    "\n",
    "        losses.backward()\n",
    "        opt.step()\n",
    "\n",
    "\n",
    "torch.save(manik.state_dict(), \"Manik-mlp-encoder\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "required = torch.randn(64);\n",
    "plt.figure(figsize=(1,1))\n",
    "\n",
    "plt.imshow(vaenc.dec(required.to(device)).detach().cpu().numpy().reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(train[1].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae4875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3841de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac92da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c5a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f96e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba393d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "manik = VAE(latent_dim).to(device)\n",
    "manik.load_state_dict(torch.load(\"MLP-VAE-Fashion_MNIST-Dataset-Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=labels.reshape(60000,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.reshape(60000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65089cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.hstack((train,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29348815",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(train[:,:-1], train[:,-1], test_size=0.95, random_state=42,stratify=train[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dead8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c4387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648d50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695cd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22febb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.stairs(counts,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214df124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SVC(kernel='linear', C=1.0, decision_function_shape='ovr')  # You can adjust the kernel and parameters\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7174821",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_function = lambda row:manik.enc(torch.tensor(row/255,dtype=torch.float32).to(device))\n",
    "train2 =[lambda_function(row) for row in (train[:,:-1])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85aaa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train2)):\n",
    "    train2[i]=train2[i].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=np.array(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=np.hstack((train2,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = np.isnan(train2).any(axis=1)\n",
    "train2 = train2[~nan_rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb02728",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train1, X_test1, y_train1, y_test1 = train_test_split(train2[:,:-1], train2[:,-1], test_size=0.95, random_state=42,stratify=train2[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4e00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1 = SVC(kernel='linear', C=1.0, decision_function_shape='ovr')  # You can adjust the kernel and parameters\n",
    "\n",
    "# Train the model\n",
    "model1.fit(X_train1, y_train1)\n",
    "\n",
    "# Make predictions on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test1, y_pred1)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb010da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softmax_prediction(x_10_dim):\n",
    "    x_10_dim = np.exp(x_10_dim - np.max(x_10_dim, keepdims=True))\n",
    "    return x_10_dim / x_10_dim.sum(keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5126c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=[]\n",
    "for i,x in enumerate(X_test):\n",
    "    input_tensor=softmanik(torch.tensor(x).to(device))\n",
    "    y=torch.argmax(F.softmax(input_tensor, dim=0))\n",
    "    ans.append(y.item()!=y_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ans)/len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23c04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e731cefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example raw scores (replace this with your own data)\n",
    "raw_scores = np.random.randn(10)\n",
    "\n",
    "# Apply softmax along axis 1 to convert to probabilities across 1024 classes\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, keepdims=True))\n",
    "    e_x / e_x.sum()\n",
    "    mx = e_x[0]\n",
    "    idx = 0\n",
    "    for i in range(1,len(e_x)):\n",
    "        if(e_x[i] > mx):\n",
    "            idx = i\n",
    "    return idx\n",
    "\n",
    "# Apply softmax to get probabilities across 10 classes\n",
    "softmax_scores = softmax(raw_scores)\n",
    "\n",
    "# Get probabilities for the first class (index 0) to the tenth class (index 9)\n",
    "probabilities_for_10_classes = softmax_scores\n",
    "\n",
    "print(\"Original Raw Scores:\")\n",
    "print(raw_scores)\n",
    "\n",
    "print(\"\\nSoftmax Applied (Probabilities for 10 Classes):\")\n",
    "print(probabilities_for_10_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95470b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abb11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca988d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae835c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98116813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2ff07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e0114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97031d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef7958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18551c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple neural network class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 64*1024)\n",
    "        self.fc2 = nn.Linear(64*1024, 1024*10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Training finished!')\n",
    "\n",
    "# Now you can use the trained network for predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5f5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manik = VAE(latent_dim).to(device)\n",
    "manik.load_state_dict(torch.load(\"MLP-VAE-Fashion_MNIST-Dataset-Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ca27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed8d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63662d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eca300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
